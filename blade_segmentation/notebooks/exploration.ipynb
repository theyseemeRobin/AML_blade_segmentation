{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv ../../.env\n",
    "\n",
    "import os, sys\n",
    "import collections\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from file_handler import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_data(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a glance, we have optical - thermal videos and images. There is a test-dev set presumably for debugging with a much larger trainval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders in test-dev: 6\n",
      "Total number of files in test-dev: 1675\n",
      "Number of folders in trainval: 30\n",
      "Total number of files in trainval: 8714\n"
     ]
    }
   ],
   "source": [
    "def get_number_of_files_in_folder(folder):\n",
    "    counter = collections.Counter()\n",
    "    for root, dirs, files in os.walk(f\"../data/Images/{folder}/Optical\"):\n",
    "        for dir in dirs:\n",
    "            counter[dir] += len(os.listdir(os.path.join(root, dir)))\n",
    "    \n",
    "    print(f'Number of folders in {folder}: {len(counter)}')\n",
    "    \n",
    "    # Total number of files\n",
    "    total = sum(counter.values())\n",
    "        \n",
    "    print(f'Total number of files in {folder}: {total}')\n",
    "    \n",
    "    return counter\n",
    "\n",
    "\n",
    "dev_counter = get_number_of_files_in_folder('test-dev')\n",
    "train_counter = get_number_of_files_in_folder('trainval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vos_benchmark.benchmark import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are *SKIPPING* the evaluation of the first and the last frame (standard for semi-supervised video object segmentation).\n",
      "In dataset ../data/optic_thermal/Images/trainval/val/DAVIS_Masks, we are evaluating on 3 videos: ['Mavic1_DJI_0872', 'Mavic1_DJI_0876', 'Mavic1_DJI_0882']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:13<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence        obj   J&F     J     F\n",
      "Global score         11.1  6.3  15.9\n",
      "Mavic1_DJI_0872 001  11.6   7.5  15.8\n",
      "Mavic1_DJI_0876 001  18.1  10.7  25.5\n",
      "Mavic1_DJI_0882 001   3.6   0.7   6.5\n",
      "\n",
      "Summary:\n",
      "Global score: J&F: 11.1 J: 6.3 F: 15.9\n",
      "Time taken: 13.48s\n",
      "J: [11.115216914350716], JF: [6.2982486238266695], F: [15.932185204874763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt_dir = \"../data/optic_thermal/Images/trainval/val/DAVIS_Masks\"\n",
    "pred_dir = \"../results/2025-01-25_17-46-41/results/Annotations\"\n",
    "\n",
    "results = benchmark([gt_dir], [pred_dir])\n",
    "\n",
    "J, JF, F = results[:3]\n",
    "print(f\"J: {J}, JF: {JF}, F: {F}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some old code I made\n",
    "def access_wandb_runs(entity=None, \n",
    "                      project=\"aml-blade-clustering\", \n",
    "                      filters={}, get_baseline=False):\n",
    "    \"\"\"\n",
    "    Retrieve and analyze runs from a Weights & Biases project\n",
    "    \n",
    "    Parameters:\n",
    "    - entity: Your wandb username or team name\n",
    "    - project: The project containing your runs\n",
    "    - filters: Optional dictionary to filter runs\n",
    "    \n",
    "    Returns:\n",
    "    - List of run objects with their details\n",
    "    \"\"\"\n",
    "    # Initialize the wandb API\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    # Get the entity from the environment variable if not provided\n",
    "    if entity is None:\n",
    "        \n",
    "        if os.getenv(\"WANDB_ENTITY\") is None:\n",
    "            raise ValueError(\"Please provide an entity or set the WANDB_ENTITY environment variable. This is your wandb username or team name\")\n",
    "        \n",
    "        entity = os.getenv(\"WANDB_ENTITY\")\n",
    "    \n",
    "    # Default filters\n",
    "    if filters is not None:\n",
    "        additional_filters = {\n",
    "            'created_at' : {\n",
    "                '$gte': '2025-02-01T00:00:00Z'    \n",
    "            },\n",
    "            'state': 'finished'\n",
    "        }\n",
    "        filters = {**filters, **additional_filters}\n",
    "    \n",
    "    # Fetch runs from the specified project\n",
    "    runs = api.runs(\n",
    "        path=f\"{entity}/{project}\", \n",
    "        filters=filters\n",
    "    )\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config.clustering_algorithm': 'kmeans', 'created_at': {'$gte': '2025-02-01T00:00:00Z'}, 'state': 'finished'}\n"
     ]
    }
   ],
   "source": [
    "runs = access_wandb_runs(filters={'config.clustering_algorithm': 'kmeans'})\n",
    "\n",
    "kmeans_df = pd.DataFrame()\n",
    "\n",
    "for run in runs:\n",
    "    metrics = run.summaryMetrics\n",
    "    F = metrics['Boundary F Measure']\n",
    "    JF = metrics['Mean']\n",
    "    J = metrics['Region Similarity']\n",
    "    fps = metrics['Frames per Second']\n",
    "    \n",
    "    num_iterations = run.config['n_iter']\n",
    "    \n",
    "    # Concat\n",
    "    kmeans_df = pd.concat([kmeans_df, pd.DataFrame({\n",
    "        'F': [F],\n",
    "        'JF': [JF],\n",
    "        'J': [J],\n",
    "        'fps': [fps],\n",
    "        'num_iter': [num_iterations]\n",
    "    })])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_map = {\n",
    "    'J': '$\\mathcal{J}$',\n",
    "    'JF': '$\\mathcal{J}\\&\\mathcal{F}$',\n",
    "    'F': '$\\mathcal{F}$',\n",
    "    'fps': 'FPS',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Num Iterations first, then J, JF, F, FPS\n",
    "kmeans_df = kmeans_df[['num_iter', 'J', 'JF', 'F', 'fps']]\n",
    "\n",
    "# Create copy\n",
    "latex_df = kmeans_df.copy()\n",
    "\n",
    "# Round to 2 decimal places\n",
    "latex_df = latex_df.round(2)\n",
    "\n",
    "# Rename num_iter to Iterations\n",
    "latex_df = latex_df.rename(columns={'num_iter': 'Iterations'})\n",
    "\n",
    "# Rename using symbol map\n",
    "latex_df = latex_df.rename(columns=symbol_map)\n",
    "\n",
    "# Change fps to FPS\n",
    "latex_df = latex_df.rename(columns={'fps': 'FPS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "Iterations & $\\mathcal{J}$ & $\\mathcal{J}\\&\\mathcal{F}$ & $\\mathcal{F}$ & FPS \\\\\n",
      "\\midrule\n",
      "2 & 16.60 & 24.43 & 8.78 & 43.38 \\\\\n",
      "4 & 13.06 & 16.33 & 9.79 & 42.61 \\\\\n",
      "8 & 19.00 & 27.59 & 10.40 & 37.14 \\\\\n",
      "16 & 19.10 & 27.62 & 10.58 & 31.52 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Latex\n",
    "print(latex_df.to_latex(index=False, float_format=\"%.2f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
